{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e256f39-5121-4b73-a8a1-f1accf548445",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating Text with an LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "072c0778-68cc-4ffb-9b25-ea0035716c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  13637\n",
      "Total Vocab:  41\n",
      "Total Patterns:  13537\n",
      "Epoch 0: Cross-entropy: 39879.5938\n",
      "Epoch 1: Cross-entropy: 39814.8555\n",
      "Epoch 2: Cross-entropy: 39797.9297\n",
      "Epoch 3: Cross-entropy: 39622.3633\n",
      "Epoch 4: Cross-entropy: 38937.0547\n",
      "Epoch 5: Cross-entropy: 38132.8203\n",
      "Epoch 6: Cross-entropy: 37738.0234\n",
      "Epoch 7: Cross-entropy: 37107.9922\n",
      "Epoch 8: Cross-entropy: 36685.9766\n",
      "Epoch 9: Cross-entropy: 36411.8008\n",
      "Epoch 10: Cross-entropy: 36269.5391\n",
      "Epoch 11: Cross-entropy: 35955.3203\n",
      "Epoch 12: Cross-entropy: 35638.4023\n",
      "Epoch 13: Cross-entropy: 35374.9375\n",
      "Epoch 14: Cross-entropy: 35158.4102\n",
      "Epoch 15: Cross-entropy: 35041.2148\n",
      "Epoch 16: Cross-entropy: 34733.2344\n",
      "Epoch 17: Cross-entropy: 34407.3008\n",
      "Epoch 18: Cross-entropy: 34150.3164\n",
      "Epoch 19: Cross-entropy: 33780.7070\n",
      "Epoch 20: Cross-entropy: 33540.3789\n",
      "Epoch 21: Cross-entropy: 33197.9297\n",
      "Epoch 22: Cross-entropy: 32690.6680\n",
      "Epoch 23: Cross-entropy: 32208.5352\n",
      "Epoch 24: Cross-entropy: 31652.2441\n",
      "Epoch 25: Cross-entropy: 31191.2051\n",
      "Epoch 26: Cross-entropy: 30456.1543\n",
      "Epoch 27: Cross-entropy: 29899.3301\n",
      "Epoch 28: Cross-entropy: 29949.7852\n",
      "Epoch 29: Cross-entropy: 28697.1035\n",
      "Epoch 30: Cross-entropy: 28120.5430\n",
      "Epoch 31: Cross-entropy: 27813.2363\n",
      "Epoch 32: Cross-entropy: 26609.9355\n",
      "Epoch 33: Cross-entropy: 26174.3965\n",
      "Epoch 34: Cross-entropy: 25010.7598\n",
      "Epoch 35: Cross-entropy: 24571.2871\n",
      "Epoch 36: Cross-entropy: 23713.3555\n",
      "Epoch 37: Cross-entropy: 23098.8594\n",
      "Epoch 38: Cross-entropy: 22324.9883\n",
      "Epoch 39: Cross-entropy: 21386.3086\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    " \n",
    "# load ascii text and covert to lowercase\n",
    "filename = \"/home/nmit/Downloads/wonderland/wonder/wonderland.txt\"\n",
    "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
    "raw_text = raw_text.lower()\n",
    " \n",
    "# create mapping of unique chars to integers\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    " \n",
    "# summarize the loaded data\n",
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)\n",
    " \n",
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    seq_in = raw_text[i:i + seq_length]\n",
    "    seq_out = raw_text[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns)\n",
    " \n",
    "# reshape X to be [samples, time steps, features]\n",
    "X = torch.tensor(dataX, dtype=torch.float32).reshape(n_patterns, seq_length, 1)\n",
    "X = X / float(n_vocab)\n",
    "y = torch.tensor(dataY)\n",
    " \n",
    "class CharModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=1, hidden_size=256, num_layers=1, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.linear = nn.Linear(256, n_vocab)\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        # take only the last output\n",
    "        x = x[:, -1, :]\n",
    "        # produce output\n",
    "        x = self.linear(self.dropout(x))\n",
    "        return x\n",
    "    \n",
    "n_epochs = 40\n",
    "batch_size = 128\n",
    "model = CharModel()\n",
    " \n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "loader = data.DataLoader(data.TensorDataset(X, y), shuffle=True, batch_size=batch_size)\n",
    " \n",
    "best_model = None\n",
    "best_loss = np.inf\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in loader:\n",
    "        y_pred = model(X_batch)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in loader:\n",
    "            y_pred = model(X_batch)\n",
    "            loss += loss_fn(y_pred, y_batch)\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            best_model = model.state_dict()\n",
    "        print(\"Epoch %d: Cross-entropy: %.4f\" % (epoch, loss))\n",
    " \n",
    "torch.save([best_model, char_to_int], \"/home/nmit/Documents/single-char.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "684ad4dd-3a6e-4bb4-9536-77c71b52d105",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating Text with an LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ad1652c-ee37-4a5e-ae7f-c423625532d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 100\n",
    "start = np.random.randint(0, len(raw_text)-seq_length)\n",
    "prompt = raw_text[start:start+seq_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccd867c5-ba48-42ec-ba6a-5183c1b911c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: \"a crimson velvet cushion; and, last of all this grand procession, came the king and queen of hearts.\"\n",
      " al ce caca  oo d sai quecl  and toild she rerte fand nn rorel  and aoong the  ai ce co cocwe then  alice could het remd no the cickes so the kaoe  fn  al the woned  aid she qait ho woete with the kicg torele an cecces, ait w shed toe dingh af rares to tee cousdon, and the hreput onee tu toiel whsh oetele ao ce coued ih  alice toite rabbit, oitt an  alice toit  and woin  uu dor tonte the rerte fand re merele aid e moip tu toese oith oo mirele aii a serg lont so tir luoking oo rert lomtle  “iu aan the wan  and soon so tee sooer  and toon do she wonte aarer hnd tee iocpusn aese here the greaess  and woon woue dand nn rer huoning oo rer luoting aoint te tee sooer sare colnnes, “hot at she wast head  “ih  an  who’ loat the rabt to tes tooklng an the dins  and a cang lo cis hod ofoee th aed tet eoonnng at ave whe gerre aed t eadi  oo the cac n vernee ao cacrre  fl cas tes rorele an tee dine  and earee  awu head tht horee an  the hese ro nei huon, and a bai   ooit then  ald toon duund the kr\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    " \n",
    "best_model, char_to_int = torch.load(\"/home/nmit/Documents/single-char.pth\")\n",
    "n_vocab = len(char_to_int)\n",
    "int_to_char = dict((i, c) for c, i in char_to_int.items())\n",
    " \n",
    "# reload the model\n",
    "class CharModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=1, hidden_size=256, num_layers=1, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.linear = nn.Linear(256, n_vocab)\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        # take only the last output\n",
    "        x = x[:, -1, :]\n",
    "        # produce output\n",
    "        x = self.linear(self.dropout(x))\n",
    "        return x\n",
    "model = CharModel()\n",
    "model.load_state_dict(best_model)\n",
    " \n",
    "# randomly generate a prompt\n",
    "filename = \"/home/nmit/Downloads/wonderland/wonder/wonderland.txt\"\n",
    "seq_length = 100\n",
    "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
    "raw_text = raw_text.lower()\n",
    "start = np.random.randint(0, len(raw_text)-seq_length)\n",
    "prompt = raw_text[start:start+seq_length]\n",
    "pattern = [char_to_int[c] for c in prompt]\n",
    " \n",
    "model.eval()\n",
    "print('Prompt: \"%s\"' % prompt)\n",
    "with torch.no_grad():\n",
    "    for i in range(1000):\n",
    "        # format input array of int into PyTorch tensor\n",
    "        x = np.reshape(pattern, (1, len(pattern), 1)) / float(n_vocab)\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "        # generate logits as output from the model\n",
    "        prediction = model(x)\n",
    "        # convert logits into one character\n",
    "        index = int(prediction.argmax())\n",
    "        result = int_to_char[index]\n",
    "        print(result, end=\"\")\n",
    "        # append the new character into the prompt for the next iteration\n",
    "        pattern.append(index)\n",
    "        pattern = pattern[1:]\n",
    "print()\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ab6095-7c3d-4b98-bb17-941b3e91f7d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
